import streamlit as st
import pandas as pd
import unicodedata
import jaconv
import requests
import io
# ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ï¼ˆå…¨è§’â†’åŠè§’ã€ã²ã‚‰ãŒãªâ‡„ã‚«ã‚¿ã‚«ãƒŠã‚‚çµ±ä¸€ã€ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆå°æ–‡å­—åŒ–ãªã©ï¼‰
def normalize_text(text):
    if pd.isna(text):
        return ''
    text = str(text)
    text = unicodedata.normalize('NFKC', text)  # â† ã“ã‚ŒãŒæ­£ã—ã„
  # å…¨è§’ãƒ»åŠè§’ã‚’çµ±ä¸€
    text = jaconv.kata2hira(text)           # ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãª ã«å¤‰æ›
    return text.lower()                     # å°æ–‡å­—åŒ–

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®Apps Scriptå…¬é–‹URL
url = "https://script.google.com/macros/s/AKfycbx6yH3M8l_eQPhx8aTUn3DUEebIUM9GM02IYuSBUwtnZNdXbnB0lzh0TDCeqUbls6wU/exec"

# ãƒ‡ãƒ¼ã‚¿å–å¾—
response = requests.get(url)
print(response.text)
df = pd.read_json(io.StringIO(response.text), orient='records')







# æ¤œç´¢å¯¾è±¡ã®åˆ—ï¼ˆå­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ä½¿ã†ï¼‰
search_columns = ['é ­æ–‡å­—', 'ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå', 'ã‚¢ãƒ«ãƒãƒ å', 'æ›²å', 'æ‰€åœ¨']
search_columns = [col for col in search_columns if col in df.columns]

# æ­£è¦åŒ–ç”¨åˆ—ã‚’è¿½åŠ 
for col in search_columns:
    df[f"æ¤œç´¢ç”¨_{col}"] = df[col].apply(normalize_text)

# Streamlit UI
st.markdown("## ğŸµ ã•ãŒã™ã‚“")

# æ¤œç´¢å…¥åŠ›
search_input = st.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢")

# æ¤œç´¢å‡¦ç†
if search_input:
    search_normalized = normalize_text(search_input)
    mask = pd.Series(False, index=df.index)
    for col in search_columns:
        key = f"æ¤œç´¢ç”¨_{col}"
        if key in df.columns:
            mask |= df[key].str.contains(search_normalized, na=False)
    df_filtered = df[mask]
else:
    df_filtered = df

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡¨ç¤ºï¼ˆæ¤œç´¢ç”¨ã®åˆ—ã¯éè¡¨ç¤ºï¼‰
st.write("ãƒ‡ãƒ¼ã‚¿ä»¶æ•°:", len(df_filtered))
st.dataframe(df_filtered[search_columns])


